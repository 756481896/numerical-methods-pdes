{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<table>\n",
    " <tr align=left><td><img align=left src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\">\n",
    " <td>Text provided under a Creative Commons Attribution license, CC-BY. All code is made available under the FSF-approved MIT license. (c) Kyle T. Mandli (and Marc Spiegelman)</td>\n",
    "</table>\n",
    "\n",
    "Much of this material was adapted from the first few chapters of [Larson and Bengzon: The Finite Element Method\n",
    "Theory, Implementation,\n",
    "and Applications](http://link.springer.com/book/10.1007%2F978-3-642-33287-6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Finite Element Methods: an introduction\n",
    "\n",
    "The Finite Element Method (FEM) provides yet another method of transforming continuous PDE's to systems of discrete linear and non-linear equations and is particularly popular in Engineering and Solid Mechanics (although the method is completely general).  Finite Elements has a rich mathematical basis in functional analysis as well a very wide range of specialized applications.  Needless to say, this subject and the accompanying literature is vast.  The purpose of these notes are just to give you a very basic introduction to some of the fundamental ideas in Finite Elements and their implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Finite Dimensional Function spaces\n",
    "\n",
    "A key idea in Finite Elements is that we will be approximating continuous functions $f(x)$ as a linear combination of a finite number of basis functions\n",
    "\n",
    "$$\n",
    "    f_h(x) = \\sum_{i=0}^N w_i \\phi_i(x)\n",
    "$$\n",
    "\n",
    "where $\\phi_i(x)$ are the basis functions and $w_i$ are a set of weights.  We've seen similar decompositions for spectral methods. However instead of using global basis functions such as $\\sin(kx)$ or Chebyshev polynomials,  we will (for the most part) use piecewise polynomials.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Piecewise Linear Functions in 1-D (P1)\n",
    "\n",
    "![](./images/P1_function_annotated_fig1.1LB.png)\n",
    "\n",
    "As an example, consider the piecewise linear \"connect the dots\" function illustrated above where we have decomposed an interval $I=[x_0,x_5]$ into 5 sub-intervals or \"elements\"  $e_i = [x_{i},x_{i+1}]$ with $i=1\\ldots 4$.  Over each of these intervals, the function $v_h$ is a linear function of $x$ and each segment is continuous at the element edge.  Figure modified from Figure 1.1 of Larson and Bengzon.  \n",
    "\n",
    "While $v_h(x)$ is a continous function that can be evaluated for any value of $x$, it should be clear that there are really only 6 degrees of freedom corresponding to the values at the nodes $\\vec v = [v_0,v_1,v_2,v_3,\\ldots,v_5]$.  By just changing these 6 numbers, we can generate an infinite number of piecewise linear functions on this triangulation.  We will call this finite dimensional space of functions $\\cal V_h$, which is fully described by a mesh of elements, and an interpolant over each element.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Global Basis Functions\n",
    "\n",
    "Given any discrete function space $\\cal V_h$, we should be able to describe any function $v_h\\in \\cal V_h$ in terms of a set of basis functions that span the space.  In the case of a 1-D piecewise linear function space, the global basis functions are given by the \"Hat Functions\"  \n",
    "\n",
    "$$\n",
    "\\phi_i(x) = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "(x - x_{i-1})/h_{i-1}, & x\\in e_{i-1} \\\\\n",
    "(x_i - x)/h_{i}, & x\\in e_{i} \\\\\n",
    "0, & \\text{otherwise} \\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "Which have the important property that $\\phi_i(x_j) = \\delta_{ij}$.  A typical hat function is shown in Figure 1.2 from Larson and Bengson.\n",
    "![](./images/P1_Hat_function_fig1.2LB.png)\n",
    "\n",
    "While it's not entirely obvious,  we can construct all piecewise linear functions in $\\cal V_h$ as a linear combination of these hat functions, i.e. \n",
    "\n",
    "$$\n",
    "f_h(x) = \\sum_{i=0}^5 w_i\\phi_i(x)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Local Basis Functions\n",
    "\n",
    "To make this a bit clearer it is worth looking at how these basis functions interpolate $v$ over a single element.\n",
    "\n",
    "![](./images/P1LocalBases.png)\n",
    "\n",
    "Consider just the portion of $v(x)$ that lies in element $e_i$.  Clearly the only global basis functions that have support in element $e_i$ are $\\phi_i(x)$ and $\\phi_{i+1}(x)$.  We claim that over this element\n",
    "$$\n",
    "v(x) = v_i\\phi_i(x) + v_{i+1}\\phi_{i+1}(x)\\quad\\text{for}\\quad x\\in [x_i,x_{i+1}]\n",
    "$$\n",
    "\n",
    "This is clearly true at the nodes because of the property that $\\phi_i(x_j) = \\delta_{ij}$.  \n",
    "\n",
    "Between the nodes, we expect that $\\phi_i$ and $\\phi_{i+1}$ provide linear interpolation.  If we just consider the *local basis functions* which are the parts of $\\phi_i$ and $\\phi_{i+1}$ in element $e_i$\n",
    "\n",
    "\\begin{align}\n",
    "  N_0(x) & = (x_{i+1} - x)/(x_{i+1} - x_i)\\\\\n",
    "  N_1(x) & = (x - x_i)/(x_{i+1} - x_i)\\\\\n",
    "\\end{align}\n",
    "\n",
    "it becomes clear that these are just the Lagrange Polynomials of order 1 that interpolate any linear function over the interval $[x_i,x_{i+1}]$.   Just to check note that if $x* = x_i + th_i$ where $t$ is the fractional distance across the element with lenght $h_i = x_{i+1} - x_i$, then\n",
    "\\begin{align}\n",
    "  N_0(x*) & = (x_{i+1} - x_i -t h_i)/h_i = (1 -t)\\\\\n",
    "  N_1(x*) & = (x_i + th_i - x_i)/h_i = t\\\\\n",
    "\\end{align}\n",
    "\n",
    "so that within $e_i$\n",
    "$$ \n",
    "   v(x) = v_i N_0(x) + v_{i+1}N_1(x) = v_i(1 - t)  + v_{i+1} t\n",
    "$$\n",
    "with $t\\in[0,1]$\n",
    "\n",
    "Thus our full function $v(x)$ over the full domain $\\Omega = [x_0,x_5]$ is just the union of these local linear pieces.  Throughout this introduction we will often move between the global view and the element view depending on which frame of reference is more convenience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Higher order polynomial Function Spaces\n",
    "\n",
    "The space of piecewise linear functions is often referred to as $P_1$ but there are other choices.  For example, the space of piecewise quadratic functions ($P_2$) has a set of local basis functions that are simply the Lagrange Polynomials of order 2 and require three degrees of freedom per node.  The global basis functions are simply constructed out of the local ones.  The Figure shows a subset of basis functions for $P_2$ which are different for degrees of freedom at the centers and edges of elements (original figure from [Introduction to Finite Element Methods](http://hplgit.github.io/INF5620/doc/pub/sphinx-fem)\n",
    "\n",
    "![](http://hplgit.github.io/INF5620/doc/pub/sphinx-fem/_images/mpl_fe_basis_p2_4e_lab.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interpolation of a function $f(x)$ onto $\\cal V$\n",
    "\n",
    "Given a set of basis functions $\\phi_i(x)$ for a function space $\\cal V$, it should be clear that not all functions can be represented exactly, without error in $\\cal V$.  For example, given a smooth function $f(x)$ the question arises how to construct approximations $f_h(x) \\in \\cal V$ that minimize some measure of the error.  Actually there are multiple approaches.  The simplest approximation is simply the *interpolation* of $f$ onto $\\cal V$ which we will denote $\\pi f$ and define as the function $\\pi f \\in \\cal V$ such that\n",
    "\n",
    "$$\n",
    "    \\pi f (x) = \\sum_{i=0}^N f(x_i)\\phi(x)\n",
    "$$\n",
    "\n",
    "Given the interpolating properties of the Lagrange polynomials, it should be clear that\n",
    "\n",
    "$$\n",
    "\\pi f(x_j) = f(x_j)\n",
    "$$\n",
    "\n",
    "i.e. the two functions have zero error at the degrees of freedom. \n",
    "Figure 1.3 from Larson and Bengzon shows the linear interpolant of a function $f$ onto a single element over the interval $[x_0,x_1]$.\n",
    "\n",
    "![](./images/f_interpolation_P1_01.png)\n",
    "\n",
    "Figure 1.4 from Larson and Bengzon shows the linear interpolant of a function $f$ onto a piecewise linear function space $\\cal V$.\n",
    "\n",
    "![](./images/f_interpolation_P1_02.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Interpolation Errors\n",
    "\n",
    "In general there will usually be an error between $f(x)$ and its interpolant $\\pi f(x)$. Quantifying this error though usually requires defining some norm and as usual there are multiple choices.  As it turns out however,  a useful norm in finite elements are the $L^2$ norm of a function over a domain $\\Omega$\n",
    "\n",
    "$$\n",
    "    ||f||_{L^2} = \\left[ \\int_\\Omega f^2 dx\\right]^{1/2}\n",
    "$$\n",
    "\n",
    "and its related norm\n",
    "\n",
    "$$\n",
    "    ||f||_{L^2(I)} = \\left[ \\int_I f^2 dx\\right]^{1/2}\n",
    "$$\n",
    "\n",
    "over a sub-interval $I$ (usually an element).\n",
    "\n",
    "Given these definitions, and the behavior of polynomial interpolation it is relatively straightforward to put the following estimates on the interpolation error\n",
    "\n",
    "* Interpolation error over a single P1 linear element\n",
    "\n",
    "$$ \n",
    "|| f - \\pi f||_{L^2(I)} \\leq C h^2||f''||_{L^2(I)}\n",
    "$$\n",
    "\n",
    "where $I = [x_i,x{i+1}]$, $h = x_{i+1} - x{i}$, C is a constant, and $||f''||_{L^2(I)}$ is a measure of the curvature of the function over the interval.  If $h=0$ or the function is linear over the interval, then the error is zero.\n",
    "\n",
    "* Interpolation error over the whole domain\n",
    "\n",
    "For a piecewise polynomial function, the errors in the interpolant onto $\\cal V$ are simply the summation of the errors over the element i.e. \n",
    "\n",
    "$$ \n",
    "|| f - \\pi f||^2_{L^2} \\leq C \\sum_{i=0}^N h_i^4||f''||^2_{L^2(I_i)}\n",
    "$$\n",
    "\n",
    "### Convergence\n",
    "\n",
    "Given these error estimates, it is clear that the interpolant converges to the continuous function in the $L^2$ norm as $h\\rightarrow 0$ which makes sense as we expect the interpolant to be a better approximation to $f$ for finer and finer meshes. For $P_1$ functions, the error converges as $h^2$,  higher order interpolants of *smooth* functions should converge more rapidly if the higher-order piecewise polynomial is a good approximation to the continuous function $f$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## $L_2$ Projection of a function $f(x)$ onto $\\cal V$\n",
    "\n",
    "While the interpolant $\\pi f$ converges to $f$ in the $L^2$ norm as $h\\rightarrow 0$, it turns out that for fixed $h$, it is not the function in $\\cal V$ with the smallest $L^2$ error.  For that problem we need the orthogonal $L^2$ projection $P_h f$ which turns out to be the unique function $v_h\\in\\cal V$ that minimizes $||f - v_h||_{L^2}$.  \n",
    "Figure 1.6 from Larson and Bengzon show the orthogonal projection of $f$ onto $\\cal V$ for $f(x) = x\\sin(\\pi x)$\n",
    "\n",
    "![](./images/f_projection_P1_01.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Relationship to Least-Squares projection in linear algebra\n",
    "\n",
    "Before we develop the machinery for calculating  the orthogonal $L^2$ projection of $f$ onto $\\cal V$, $P_h f$,it is probably worth reviewing, briefly the related orthongal projection problem from linear algebra. \n",
    "\n",
    "![](./images/projection_figure.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a 2-dimensional subspace $\\cal S$ of $R^3$ spanned by two linearly independent 3-D vectors $\\boldsymbol{a}_1$ and $\\boldsymbol{a}_2$. i.e.\n",
    "\n",
    "$$\n",
    "\\cal S = \\mathrm{span}<\\boldsymbol{a}_1,\\boldsymbol{a}_2>\n",
    "$$ \n",
    "\n",
    "Let $\\boldsymbol{b}$ be a third vector not in $\\cal S$.  The problem is to find the point $\\boldsymbol{p} \\in \\cal S$ that minimizes the Euclidian 2-norm of the error $\\boldsymbol{e} = \\boldsymbol{b} - \\boldsymbol{p}$ where $||\\boldsymbol{e}||_2 = \\sqrt{\\boldsymbol{e}^T\\boldsymbol{e}}$\n",
    "\n",
    "Inspection of the figure shows geometrically that the shortest error will be to find the point $\\boldsymbol{p} = x_1\\boldsymbol{a}_1 + x_2\\boldsymbol{a}_2$ such that $\\boldsymbol{e}$ is orthogonal to the plane $\\cal S$.  If we define a matrix \n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "    \\boldsymbol{a}_1 & \\boldsymbol{a}_2\n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "whose columns are the vectors $\\boldsymbol{a}_1$ and $\\boldsymbol{a}_2$, then $\\boldsymbol{p} = A\\boldsymbol{x}$ where \n",
    "\n",
    "$$\n",
    "\\boldsymbol{x} = \\begin{bmatrix}\n",
    "    x_1\\\\\n",
    "    x_2\n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Now for $\\boldsymbol{e}$ to be orthogonal to every vector in $\\cal S$ it is sufficient for it to orthogonal to the basis vectors $\\boldsymbol{a}_1$ and $\\boldsymbol{a}_2$.  Thus the requirement of orthogonality is that \n",
    "\n",
    "$$\n",
    "    \\boldsymbol{a}_i^T\\boldsymbol{e} = 0\n",
    "$$\n",
    "\n",
    "for $i=1,2$.  This is equivalent to the statement $A^T\\boldsymbol{e}=\\boldsymbol{0}$  (or that the error is in the Left null space of $A$).\n",
    "\n",
    "But\n",
    "\\begin{align}\n",
    "    A^T\\boldsymbol{e} & = A^T(\\boldsymbol{b} - \\boldsymbol{p}) \\\\\n",
    "                      & = A^T(\\boldsymbol{b} - A\\boldsymbol{x}) \\\\\n",
    "                      & = \\boldsymbol{0}\n",
    "\\end{align}\n",
    "\n",
    "or the Least-squares solution requires solving the Normal Equations\n",
    "\n",
    "$$\n",
    "    A^TA\\boldsymbol{x} = A^T\\boldsymbol{b}\n",
    "$$\n",
    "\n",
    "(although the numerically sensible  way to solve this is to actually use the QR factorization which is another application of orthogonal projection)\n",
    "\n",
    "Given a solution $\\boldsymbol{x}$, the projection is simply $\\boldsymbol{p} = A\\boldsymbol{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Orthogonal Projection of a function onto a discrete Function Space\n",
    "\n",
    "If you understand the previous problem from linear algebra,  you'll realize that orthogonal projection of a function onto a discrete function space is essentially the same problem with slightly different machinery.  \n",
    "\n",
    "The problem can be stated:\n",
    "\n",
    "Given a continuous function $f(x)$ and discrete function space $\\cal V_h$,  find the function $P_h f\\in \\cal V_h$ that minimizes $ || f - P_h f||_{L^2}$.  \n",
    "\n",
    "Again, we can construct the problem geometrically.  First if $P_h f \\in \\cal V_h$ then we can write it in terms of the basis functions of $\\cal V_h$ i.e.\n",
    "\n",
    "$$\n",
    "    P_h f(x)  = \\sum_{j=0}^N w_j\\phi_j(x)\n",
    "$$\n",
    "\n",
    "Next we construct the residual (or error) as\n",
    "\n",
    "$$ \n",
    "    r(x) = f(x) - P_h f(x) \n",
    "$$\n",
    "and require that the residual is \"orthogonal\" to every function $v_h\\in \\cal V_h$ where we define orthogonality of functions with respect to the $L^2$ norm in the usual way.  i.e. we say that $f$ and $g$ are orthogonal functions if\n",
    "\n",
    "$$\n",
    "    \\int_\\Omega fg dx = 0\n",
    "$$\n",
    "\n",
    "Therefore for $r$ to be orthogonal to every function $v_h\\in \\cal V_h$, it is only required that it be orthogonal to every basis function of $\\cal V_h$.  For a finite dimensional function space the problem becomes find $P_h f \\in \\cal V_h$ such that\n",
    "\n",
    "$$ \n",
    "    \\int_\\Omega \\phi_i(x) r(x) dx = 0\n",
    "$$ \n",
    "for all $i=0,\\ldots,N$.  \n",
    "\n",
    "Using our definitions for $r(x)$ and $P_h f(x)$, the problem becomes,  find the vector of weights $\\boldsymbol{w} = [ w_0, w_1,\\ldots, w_N]^T$ such that\n",
    "\n",
    "$$\n",
    "    \\int_\\Omega \\phi_i(x)\\sum_{j=0}^N w_j\\phi_j(x) dx = \\int_\\Omega \\phi_i(x) f(x) dx\n",
    "$$ \n",
    "for all $i=0,\\ldots,N$.  \n",
    "\n",
    "Now the RHS of this equation is a set of $N$ numbers that describes how each basis function samples $f$. Defining\n",
    "\n",
    "$$\n",
    "    \\tilde{f}_i = \\int_\\Omega \\phi_i(x) f(x) dx\\quad i=0,\\ldots,N\n",
    "$$\n",
    "the RHS assembles into a vector $\\tilde{\\boldsymbol{f}}\\in R^{N+1}$.  \n",
    "\n",
    "The LHS is a bit more complicated but we can interchange summation and integration to rewrite the LHS as\n",
    "\n",
    "$$\n",
    "\\int_\\Omega \\phi_i(x)\\sum_{j=0}^N w_j\\phi_j(x) dx = \\sum_{j=0}^N w_j\\int_\\Omega \\phi_i(x)\\phi_j(x) dx\n",
    "$$\n",
    "\n",
    "Now the final definite integrals are another set of doubly indexed numbers\n",
    "\n",
    "$$\n",
    "    M_{ij} = \\int_\\Omega \\phi_i(x)\\phi_j(x) dx\n",
    "$$\n",
    "\n",
    "which define the entries of the \"Mass Matrix\" $M$.  \n",
    "\n",
    "Thus the projection problem actually reduces to a Linear algebra problem solve \n",
    "$$\n",
    "    M\\boldsymbol{w} = \\tilde{\\boldsymbol{f}}\n",
    "$$\n",
    "for $\\boldsymbol{w}$ then $P_h f(x)$ is defined by the weights and basis functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Structure of the Mass Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Mechanics:  Assembly "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Convergence/Optimality ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
